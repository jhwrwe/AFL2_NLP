{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b5a1f2-151c-4640-bcd3-0c7891e0057a",
   "metadata": {},
   "source": [
    "# 1. Background Problem (20%)\n",
    "Language modeling is a fundamental task in Natural Language Processing (NLP), used in various applications like predictive typing, text generation, and spelling correction. For this project, I chose the Sci-Fi Stories Text Corpus available on Kaggle. Sci-Fi literature is linguistically rich and imaginative, often pushing boundaries of vocabulary and structure. Modeling such text is both challenging and rewarding, and it provides an exciting opportunity to explore how well statistical language models and autocorrect systems can handle complex and creative writing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4472924f",
   "metadata": {},
   "source": [
    "# 2. Resource\n",
    "\n",
    "We used the following dataset found from kaggle:\n",
    "\n",
    "Sci-Fi Stories Text Corpus by Jannes Klaas: \n",
    "- https://www.kaggle.com/datasets/jannesklaas/scifi-stories-text-corpus\n",
    "\n",
    "The dataset contains a collection of sci-fi short stories in plain text, which provides an ideal source for both syntactic and lexical modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0eaaf9",
   "metadata": {},
   "source": [
    "# 3. Methods (10%)\n",
    "## We applied the following methods:\n",
    "\n",
    "- Preprocessing:\n",
    "    * Lowercasing all text\n",
    "    * Removing punctuation\n",
    "    * Tokenizing into words\n",
    "\n",
    "- Model Building:\n",
    "    * Bigram Language Model (word-based)\n",
    "    * Trigram Language Model\n",
    "\n",
    "- Advanced Method:\n",
    "    * Autocorrect using edit distance and bigram probability re-ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8e77a7",
   "metadata": {},
   "source": [
    "## 4. Model Implementation Code (50%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3340b42a",
   "metadata": {},
   "source": [
    "# 5. Evaluation of Model\n",
    "## 5a. Performance Metrics (10%)\n",
    "Since this is a language generation and correction task, we use qualitative evaluation:\n",
    "- Coherence of generated sentences\n",
    "- Accuracy of autocorrect predictions (manually tested)\n",
    "\n",
    "## 5b. Evaluation Code & Result\n",
    "We evaluate our model using the following code to generate:\n",
    "- A sentence from the bigram model\n",
    "- Autocorrect outputs for various intentionally misspelled words\n",
    "\n",
    "This demonstrates the qualitative performance of the language model and correction system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2894f327",
   "metadata": {},
   "source": [
    "# 6. Conclusion & Future Work (5%)\n",
    "Our bigram and trigram models were able to generate reasonable Sci-Fi themed text based on the training corpus. The autocorrect system showed good potential in correcting common misspellings using both edit distance and word frequency.\n",
    "\n",
    "Future work:\n",
    "- Use of smoothing techniques for unseen n-grams\n",
    "- Implementation of transformer-based models (e.g., GPT)\n",
    "- Better evaluation using a held-out test set and BLEU/Perplexity scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
